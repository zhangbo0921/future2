# 环境配置

## 常用命令

### 查看/修改hostname

#### 方法1(无需重启，推荐)

```bash
# 方法1：修改haostname
hostnamectl set-hostname zyqh01
```

#### 方法2（需要重启，才能生效）

```bash
# 方法2：修改hostname
vi /etc/hostname
```

```bash
# 原hostname
# localhost.localdomain
# 修改后的
zyqh01
```

#### 方法3(临时修改，重启无效)

```
hostname zyqh01
```

#### 查看

```bash
# 查看hostname
hostname
# 结果
zyqh01
```

### 关闭防火墙

```bash
# 禁止开机启动
systemctl disable firewalld
# 关闭防火墙
systemctl stop firewalld

# 查看防火墙状态
systemctl status firewalld

● firewalld.service - firewalld - dynamic firewall daemon
   Loaded: loaded (/usr/lib/systemd/system/firewalld.service; enabled; vendor preset: enabled)
   Active: inactive (dead) since Mon 2021-02-08 22:10:22 EST; 6s ago
     Docs: man:firewalld(1)
  Process: 696 ExecStart=/usr/sbin/firewalld --nofork --nopid $FIREWALLD_ARGS (code=exited, status=0/SUCCESS)
 Main PID: 696 (code=exited, status=0/SUCCESS)
```

**Active inactive (dead)**：说明防火墙已经关闭

### 关闭SELinux

```bash
# 临时关闭，重启失效
setenforce 0

# 永久关闭，需要重启
vi /etc/selinux/config
# 将SELINUX=enforcing改为SELINUX=disabled

# 查看SELinux状态
getenforce
```

### 关闭Swap

```bash
# 临时关闭，重启失效
swapoff -a

# 永久关闭
# 1. 注释/etc/fstab关于swap的配置
vi /etc/fstab
#/dev/mapper/centos-swap swap                    swap    defaults        0 0
# 2.创建文件并写入数据
echo vm.swappiness=0 >> /etc/sysctl.con
# 3.重启
reboot

# 查看swap状态
free -h

# 结果如下：
              total        used        free      shared  buff/cache   available
Mem:           1.8G        196M        1.4G        9.5M        167M        1.4G
Swap:            0B          0B          0B

# Swap全部为 0 表示关闭了。

# total 是总内存，used是已经使用内存，free是空闲内存，shared程序共享内存，buff/cache缓存内存，available为最终可用内存
# Centos7 不需要自己计算，直接查看available就可以了。
```

### 时间同步

```bash
# 安装时间同步工具
yum -y install ntpdate

# 设置同步服务器
ntpdate time.windows.com
```

### 设置中国时区

```bash
# 设置时区为亚洲上海
timedatectl set-timezone Asia/Shanghai
reboot
```

### 查看系统时间/日期

```bash
# 日期格式化
date +'%F %X'
# 结果
2021-02-09 10:36:13 PM
```

## Docker 安装

### CentOS 7 (使用yum进行安装)

```shell
# step 1: 安装必要的一些系统工具
sudo yum install -y yum-utils device-mapper-persistent-data lvm2
# Step 2: 添加软件源信息
sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
# Step 3: 更新并安装 Docker-CE
sudo yum makecache fast
sudo yum -y install docker-ce
# Step 4: 开启Docker服务
sudo service docker start
# Step 5: 开机启动Docker服务
sudo systemctl enable docker

注意：其他注意事项在下面的注释中
# 官方软件源默认启用了最新的软件，您可以通过编辑软件源的方式获取各个版本的软件包。例如官方并没有将测试版本的软件源置为可用，你可以通过以下方式开启。同理可以开启各种测试版本等。
# vim /etc/yum.repos.d/docker-ce.repo
#   将 [docker-ce-test] 下方的 enabled=0 修改为 enabled=1
#
# 安装指定版本的Docker-CE:
# Step 1: 查找Docker-CE的版本:
# yum list docker-ce.x86_64 --showduplicates | sort -r
#   Loading mirror speeds from cached hostfile
#   Loaded plugins: branch, fastestmirror, langpacks
#   docker-ce.x86_64            17.03.1.ce-1.el7.centos            docker-ce-stable
#   docker-ce.x86_64            17.03.1.ce-1.el7.centos            @docker-ce-stable
#   docker-ce.x86_64            17.03.0.ce-1.el7.centos            docker-ce-stable
#   Available Packages
# Step2 : 安装指定版本的Docker-CE: (VERSION 例如上面的 17.03.0.ce.1-1.el7.centos)
# sudo yum -y install docker-ce-[VERSION]
# 注意：在某些版本之后，docker-ce安装出现了其他依赖包，如果安装失败的话请关注错误信息。例如 docker-ce 17.03 之后，需要先安装 docker-ce-selinux。
# yum list docker-ce-selinux- --showduplicates | sort -r
# sudo yum -y install docker-ce-selinux-[VERSION]

# 通过经典网络、VPC网络内网安装时，用以下命令替换Step 2中的命令
# 经典网络：
# sudo yum-config-manager --add-repo http://mirrors.aliyuncs.com/docker-ce/linux/centos/docker-ce.repo
# VPC网络：
# sudo yum-config-manager --add-repo http://mirrors.could.aliyuncs.com/docker-ce/linux/centos/docker-ce.repo
```

### Ubuntu 14.04 16.04 (使用apt-get进行安装)

```shell
# step 1: 安装必要的一些系统工具
sudo apt-get update
sudo apt-get -y install apt-transport-https ca-certificates curl software-properties-common
# step 2: 安装GPG证书
curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -
# Step 3: 写入软件源信息
sudo add-apt-repository "deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable"
# Step 4: 更新并安装 Docker-CE
sudo apt-get -y update
sudo apt-get -y install docker-ce

注意：其他注意事项在下面的注释中
# 安装指定版本的Docker-CE:
# Step 1: 查找Docker-CE的版本:
# apt-cache madison docker-ce
#   docker-ce | 17.03.1~ce-0~ubuntu-xenial | http://mirrors.aliyun.com/docker-ce/linux/ubuntu xenial/stable amd64 Packages
#   docker-ce | 17.03.0~ce-0~ubuntu-xenial | http://mirrors.aliyun.com/docker-ce/linux/ubuntu xenial/stable amd64 Packages
# Step 2: 安装指定版本的Docker-CE: (VERSION 例如上面的 17.03.1~ce-0~ubuntu-xenial)
# sudo apt-get -y install docker-ce=[VERSION]

# 通过经典网络、VPC网络内网安装时，用以下命令替换Step 2、Step 3中的命令
# 经典网络：
# curl -fsSL http://mirrors.aliyuncs.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -
# sudo add-apt-repository "deb [arch=amd64] http://mirrors.aliyuncs.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable"
# VPC网络：
# curl -fsSL http://mirrors.cloud.aliyuncs.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -
# sudo add-apt-repository "deb [arch=amd64] http://mirrors.cloud.aliyuncs.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable"
```

### 镜像加速

```bash
sudo mkdir -p /etc/docker
sudo tee /etc/docker/daemon.json <<-'EOF'
{
  "registry-mirrors": ["https://3nnzwyqy.mirror.aliyuncs.com"]
}
EOF
sudo systemctl daemon-reload
sudo systemctl restart docker
```



### 安装校验

```bash
root@iZbp12adskpuoxodbkqzjfZ:$ docker version

Client:
 Version:      17.03.0-ce
 API version:  1.26
 Go version:   go1.7.5
 Git commit:   3a232c8
 Built:        Tue Feb 28 07:52:04 2017
 OS/Arch:      linux/amd64

Server:
 Version:      17.03.0-ce
 API version:  1.26 (minimum version 1.12)
 Go version:   go1.7.5
 Git commit:   3a232c8
 Built:        Tue Feb 28 07:52:04 2017
 OS/Arch:      linux/amd64
 Experimental: false
```

## Centos7 网络配置

```
vi /etc/sysconfig/network-scripts/ifcfg-ens33

systemctl restart network
```

```properties
TYPE=Ethernet
PROXY_METHOD=none
BROWSER_ONLY=no
BOOTPROTO=static
DEFROUTE=yes
IPV4_FAILURE_FATAL=no
IPV6INIT=yes
IPV6_AUTOCONF=yes
IPV6_DEFROUTE=yes
IPV6_FAILURE_FATAL=no
IPV6_ADDR_GEN_MODE=stable-privacy
NAME=ens33
UUID=b6541eb0-d616-4ad6-91f7-46b10a41bbe6
DEVICE=ens33
ONBOOT=yes
IPADDR=192.168.1.20
GATEWAY=192.168.1.1
DNS1=114.114.114.114
```

主要修改

- BOOTPROTO=static 静态IP
- ONBOOT=yes 启动是启用
- IPADDR=192.168.1.20
- GATEWAY=192.168.1.1
- DNS1=114.114.114.114

### 安装工具包

```bash
yum -y install net-tools.x86_64
```

### 查看IP信息

```bash
# 查看IP信息
ifconfig

# 查询结果
ens33: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet 192.168.1.20  netmask 255.255.255.0  broadcast 192.168.1.255
        inet6 240e:358:fc5:a900:2d2:1d39:91a4:d81d  prefixlen 64  scopeid 0x0<global>
        inet6 fe80::79c8:3cfc:b047:4144  prefixlen 64  scopeid 0x20<link>
        ether 00:0c:29:2b:4b:a5  txqueuelen 1000  (Ethernet)
        RX packets 10349  bytes 13756857 (13.1 MiB)
        RX errors 0  dropped 98  overruns 0  frame 0
        TX packets 5119  bytes 472490 (461.4 KiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

lo: flags=73<UP,LOOPBACK,RUNNING>  mtu 65536
        inet 127.0.0.1  netmask 255.0.0.0
        inet6 ::1  prefixlen 128  scopeid 0x10<host>
        loop  txqueuelen 1000  (Local Loopback)
        RX packets 276  bytes 23972 (23.4 KiB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 276  bytes 23972 (23.4 KiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
```

其中，ens33代表网卡，inet 代表IP地址（192.168.1.20）

## Kubernetes集群安装

### 环境要求

1. **一台或多台机器，操作系统Centos7.x-86_x64**
2. **每台机器 2 GB 或更多的 RAM （如果少于这个数字将会影响你应用的运行内存)** 
3. **每台机器2 CPU 核或更多**
4. **集群内各机器之间能相互通信**
5. **集群内各个机器可以访问外网**
6. **节点之中不可以有重复的主机名、MAC 地址或 product_uuid**
7. **为了保证 kubelet 正常工作，禁止swap分区**

### 环境检查

#### 确保每个节点上 MAC 地址和 product_uuid 的唯一性

- 你可以使用命令 `ip link` 或 `ifconfig -a` 来获取网络接口的 MAC 地址
- 可以使用 `cat /sys/class/dmi/id/product_uuid` 命令对 product_uuid 校验

#### 关闭防火墙

```bash
# 禁止开机启动
systemctl disable firewalld
# 关闭防火墙
systemctl stop firewalld
```

#### 关闭SELinux

```bash
# 临时关闭，重启失效
setenforce 0

# 永久关闭，需要重启
vi /etc/selinux/config
# 将SELINUX=enforcing改为SELINUX=disabled

# 查看SELinux状态
getenforce
```

#### 关闭Swap

```bash
# 临时关闭，重启失效
swapoff -a

# 永久关闭
# 1. 注释/etc/fstab关于swap的配置
vi /etc/fstab
#/dev/mapper/centos-swap swap                    swap    defaults        0 0
# 2.创建文件并写入数据
echo vm.swappiness=0 >> /etc/sysctl.con
# 3.重启
reboot

# 查看swap状态
free -h
```

#### 时间同步

```bash
# 安装时间同步工具
yum -y install ntpdate

# 设置同步服务器
ntpdate time.windows.com

# 日期格式化
date +'%F %X'
```

#### 设置中国时区

```bash
# 设置时区为亚洲上海
timedatectl set-timezone Asia/Shanghai
reboot
```

#### 修改hostname

```bash
# 方法1：修改haostname
hostnamectl set-hostname zyqh01
```

#### 修改hosts

```
vi /etc/hosts

192.168.1.100 zyqh01
192.168.1.101 zyqh02
192.168.1.102 zyqh03
192.168.1.103 zyqh04
192.168.1.104 zyqh05
```



#### 允许 iptables 检查桥接流量

确保 `br_netfilter` 模块被加载。这一操作可以通过运行 `lsmod | grep br_netfilter` 来完成。若要显式加载该模块，可执行 `sudo modprobe br_netfilter`。

为了让你的 Linux 节点上的 iptables 能够正确地查看桥接流量，你需要确保在你的 `sysctl` 配置中将 `net.bridge.bridge-nf-call-iptables` 设置为 1。例如：

```bash
cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
br_netfilter
EOF

cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF

sudo sysctl --system
```

#### 检查所有端口

##### 控制平面节点

| 协议 | 方向 | 端口范围  | 作用                    | 使用者                       |
| ---- | ---- | --------- | ----------------------- | ---------------------------- |
| TCP  | 入站 | 6443      | Kubernetes API 服务器   | 所有组件                     |
| TCP  | 入站 | 2379-2380 | etcd 服务器客户端 API   | kube-apiserver, etcd         |
| TCP  | 入站 | 10250     | Kubelet API             | kubelet 自身、控制平面组件   |
| TCP  | 入站 | 10251     | kube-scheduler          | kube-scheduler 自身          |
| TCP  | 入站 | 10252     | kube-controller-manager | kube-controller-manager 自身 |

##### 工作节点

| 协议 | 方向 | 端口范围    | 作用           | 使用者                     |
| ---- | ---- | ----------- | -------------- | -------------------------- |
| TCP  | 入站 | 10250       | Kubelet API    | kubelet 自身、控制平面组件 |
| TCP  | 入站 | 30000-32767 | NodePort 服务† | 所有组件                   |

### 安装容器运行时（Docker）

请参照上文 Docker安装

#### 安装 kubeadm、kubelet 和 kubectl

##### 修改yum源

```bash
cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF
```

##### 安装kubeadmin kubeadm kubectl

```bash
yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes

systemctl enable --now kubelet
```

**kubelet 现在每隔几秒就会重启，因为它陷入了一个等待 kubeadm 指令的死循环**

#### 初始化集群(Master执行)

```bash
kubeadm init \
--apiserver-advertise-address=192.168.1.100 \
--image-repository registry.aliyuncs.com/google_containers \
--kubernetes-version v1.20.2 \
--service-cidr=10.96.0.0/12 \
--pod-network-cidr=10.244.0.0/16
```

如果你是普通用户，则需要运行一下命令：

```bash
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
```

如果你是root用户，则可以执行一下命令：

```bash
export KUBECONFIG=/etc/kubernetes/admin.conf
```

#### 节点加入集群(计算节点执行)

```bash
kubeadm join 192.168.1.100:6443 --token a129f4.wt9oqudbjo88mher \
    --discovery-token-ca-cert-hash sha256:2d06d8c8e28886df6e054b1c67a176cbf4b3e0bbaf1458b06808c71ec725a356 
```

在各个计算节点执行此命令，就会加入到集群

此时，查看集群节点

```bash
kubectl get nodes

# NAME     STATUS   ROLES                  AGE   VERSION
zyqh01   NotReady    control-plane,master   49m   v1.20.2
zyqh02   NotReady    <none>                 10m   v1.20.2
```

发现，STATUS都是NotReady，这是因为，还需要安装网络插件。

#### 部署CNI网络插件

```bash
kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
```

由于网络原因，可能会失败，多次尝试吧

#### 查看系统pod

等待一会，用一下命令查询系统pod

```bash
kubectl get pods -n kube-system

# NAME                             READY   STATUS                  RESTARTS   AGE
coredns-7f89b7bc75-4jj5h         0/1     Pending                 0          65m
coredns-7f89b7bc75-s8p8t         0/1     Pending                 0          65m
etcd-zyqh01                      1/1     Running                 1          65m
kube-apiserver-zyqh01            1/1     Running                 1          65m
kube-controller-manager-zyqh01   1/1     Running                 1          65m
kube-flannel-ds-rwv2x            0/1     Init:ErrImagePull       0          37s
kube-flannel-ds-whlcz            0/1     Init:ImagePullBackOff   0          37s
kube-proxy-bd9t4                 1/1     Running                 1          65m
kube-proxy-qdvkf                 1/1     Running                 0          15m
kube-scheduler-zyqh01            1/1     Running                 1          65m

kubectl get pods -n kube-system
#NAME                             READY   STATUS    RESTARTS   AGE
coredns-7f89b7bc75-4jj5h         1/1     Running   0          67m
coredns-7f89b7bc75-s8p8t         1/1     Running   0          67m
etcd-zyqh01                      1/1     Running   1          67m
kube-apiserver-zyqh01            1/1     Running   1          67m
kube-controller-manager-zyqh01   1/1     Running   1          67m
kube-flannel-ds-rwv2x            1/1     Running   0          2m14s
kube-flannel-ds-whlcz            1/1     Running   0          2m14s
kube-proxy-bd9t4                 1/1     Running   1          67m
kube-proxy-qdvkf                 1/1     Running   0          16m
kube-scheduler-zyqh01            1/1     Running   1          67m
```

当STATUS都是Running时，就启动好了，这个时候可以在查看各个计算节点是否准备就绪

#### 查看节点

```bash
kubectl get nodes

# NAME     STATUS   ROLES                  AGE   VERSION
zyqh01   Ready    control-plane,master   69m   v1.20.2
zyqh02   Ready    <none>                 18m   v1.20.2

```

同样的，STATUS都是Ready，表示所有节点已经准备就绪

#### 集群测试

K8s上部署一个Nginx

````bash
# 创建nginx
kubectl create deployment nginx --image=nginx
# 暴露端口
kubectl expose deployment nginx --port=80 --type=NodePort
# 查看pod端口信息
kubectl get pod,svc

#NAME                 TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE
service/kubernetes   ClusterIP   10.96.0.1        <none>        443/TCP        85m
service/nginx        NodePort    10.108.228.255   <none>        80:32415/TCP   17s
````

**访问Nginx**

使用集群中任意一个节点的IP+端口32415就可以访问到

http://192.168.1.100:32415

http://192.168.1.101:32415

